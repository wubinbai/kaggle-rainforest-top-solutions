{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "round-samoa",
   "metadata": {
    "papermill": {
     "duration": 0.015522,
     "end_time": "2021-04-04T00:57:04.550199",
     "exception": false,
     "start_time": "2021-04-04T00:57:04.534677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cathedral-advocate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:57:04.598644Z",
     "iopub.status.busy": "2021-04-04T00:57:04.585997Z",
     "iopub.status.idle": "2021-04-04T00:58:01.111798Z",
     "shell.execute_reply": "2021-04-04T00:58:01.110265Z"
    },
    "papermill": {
     "duration": 56.547025,
     "end_time": "2021-04-04T00:58:01.111983",
     "exception": false,
     "start_time": "2021-04-04T00:57:04.564958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/timm-pytorch-image-models/pytorch-image-models-master\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.4.6) (1.7.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.4.6) (0.8.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.6) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.6) (3.7.4.3)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.6) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.6) (1.19.5)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.6) (7.2.0)\r\n",
      "Building wheels for collected packages: timm\r\n",
      "  Building wheel for timm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for timm: filename=timm-0.4.6-py3-none-any.whl size=292256 sha256=2cf8154825528019f916252583f65c04dd77a168914d1bb0b807c8ec69a12d50\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b2/4e/24/ca2e6fc7fceb1e8f1f4d3e5dd21df64327a03cf318d915c1bb\r\n",
      "Successfully built timm\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.4.6\r\n",
      "Processing /kaggle/input/torchlibrosa/torchlibrosa-0.0.5-py3-none-any.whl\r\n",
      "Installing collected packages: torchlibrosa\r\n",
      "Successfully installed torchlibrosa-0.0.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/timm-pytorch-image-models/pytorch-image-models-master/\n",
    "!pip install ../input/torchlibrosa/torchlibrosa-0.0.5-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-coast",
   "metadata": {
    "papermill": {
     "duration": 0.017534,
     "end_time": "2021-04-04T00:58:01.147744",
     "exception": false,
     "start_time": "2021-04-04T00:58:01.130210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "configured-sensitivity",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:01.191458Z",
     "iopub.status.busy": "2021-04-04T00:58:01.190646Z",
     "iopub.status.idle": "2021-04-04T00:58:06.765502Z",
     "shell.execute_reply": "2021-04-04T00:58:06.764443Z"
    },
    "papermill": {
     "duration": 5.600397,
     "end_time": "2021-04-04T00:58:06.765642",
     "exception": false,
     "start_time": "2021-04-04T00:58:01.165245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import audioread\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-charm",
   "metadata": {
    "papermill": {
     "duration": 0.017042,
     "end_time": "2021-04-04T00:58:06.800252",
     "exception": false,
     "start_time": "2021-04-04T00:58:06.783210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "renewable-single",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:06.847116Z",
     "iopub.status.busy": "2021-04-04T00:58:06.845230Z",
     "iopub.status.idle": "2021-04-04T00:58:06.847682Z",
     "shell.execute_reply": "2021-04-04T00:58:06.848086Z"
    },
    "papermill": {
     "duration": 0.030842,
     "end_time": "2021-04-04T00:58:06.848227",
     "exception": false,
     "start_time": "2021-04-04T00:58:06.817385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "    \n",
    "def get_logger(out_file=None):\n",
    "    logger = logging.getLogger()\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    logger.handlers = []\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        fh = logging.FileHandler(out_file)\n",
    "        fh.setFormatter(formatter)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        logger.addHandler(fh)\n",
    "    logger.info(\"logger set up\")\n",
    "    return logger\n",
    "    \n",
    "    \n",
    "@contextmanager\n",
    "def timer(name: str, logger: Optional[logging.Logger] = None):\n",
    "    t0 = time.time()\n",
    "    msg = f\"[{name}] start\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "    yield\n",
    "\n",
    "    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "victorian-mineral",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:06.888611Z",
     "iopub.status.busy": "2021-04-04T00:58:06.888094Z",
     "iopub.status.idle": "2021-04-04T00:58:06.894973Z",
     "shell.execute_reply": "2021-04-04T00:58:06.894123Z"
    },
    "papermill": {
     "duration": 0.029504,
     "end_time": "2021-04-04T00:58:06.895093",
     "exception": false,
     "start_time": "2021-04-04T00:58:06.865589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-04 00:58:06,885 - INFO - logger set up\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger(\"main.log\")\n",
    "set_seed(1213)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-maple",
   "metadata": {
    "papermill": {
     "duration": 0.017747,
     "end_time": "2021-04-04T00:58:06.930432",
     "exception": false,
     "start_time": "2021-04-04T00:58:06.912685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hispanic-carpet",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:06.992048Z",
     "iopub.status.busy": "2021-04-04T00:58:06.969872Z",
     "iopub.status.idle": "2021-04-04T00:58:06.994706Z",
     "shell.execute_reply": "2021-04-04T00:58:06.994178Z"
    },
    "papermill": {
     "duration": 0.045932,
     "end_time": "2021-04-04T00:58:06.994819",
     "exception": false,
     "start_time": "2021-04-04T00:58:06.948887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    ######################\n",
    "    # Globals #\n",
    "    ######################\n",
    "    seed = 1213\n",
    "    epochs = 35\n",
    "    train = True\n",
    "    folds = [0]\n",
    "    img_size = 224\n",
    "    main_metric = \"epoch_f1_at_05\"\n",
    "    minimize_metric = False\n",
    "\n",
    "    ######################\n",
    "    # Data #\n",
    "    ######################\n",
    "    train_datadir = Path(\"../input/birdclef-2021/train_short_audio\")\n",
    "    train_csv = \"../input/birdclef-2021/train_metadata.csv\"\n",
    "    train_soundscape = \"../input/birdclef-2021/train_soundscape_labels.csv\"\n",
    "\n",
    "    ######################\n",
    "    # Dataset #\n",
    "    ######################\n",
    "    transforms = {\n",
    "        \"train\": [{\"name\": \"Normalize\"}],\n",
    "        \"valid\": [{\"name\": \"Normalize\"}],\n",
    "        \"test\": [{\"name\": \"Normalize\"}]\n",
    "    }\n",
    "    period = 20\n",
    "    n_mels = 128\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    sample_rate = 32000\n",
    "    melspectrogram_parameters = {\n",
    "        \"n_mels\": 224,\n",
    "        \"fmin\": 20,\n",
    "        \"fmax\": 16000\n",
    "    }\n",
    "\n",
    "    target_columns = [\n",
    "        'acafly', 'acowoo', 'aldfly', 'ameavo', 'amecro',\n",
    "        'amegfi', 'amekes', 'amepip', 'amered', 'amerob',\n",
    "        'amewig', 'amtspa', 'andsol1', 'annhum', 'astfly',\n",
    "        'azaspi1', 'babwar', 'baleag', 'balori', 'banana',\n",
    "        'banswa', 'banwre1', 'barant1', 'barswa', 'batpig1',\n",
    "        'bawswa1', 'bawwar', 'baywre1', 'bbwduc', 'bcnher',\n",
    "        'belkin1', 'belvir', 'bewwre', 'bkbmag1', 'bkbplo',\n",
    "        'bkbwar', 'bkcchi', 'bkhgro', 'bkmtou1', 'bknsti', 'blbgra1',\n",
    "        'blbthr1', 'blcjay1', 'blctan1', 'blhpar1', 'blkpho',\n",
    "        'blsspa1', 'blugrb1', 'blujay', 'bncfly', 'bnhcow', 'bobfly1',\n",
    "        'bongul', 'botgra', 'brbmot1', 'brbsol1', 'brcvir1', 'brebla',\n",
    "        'brncre', 'brnjay', 'brnthr', 'brratt1', 'brwhaw', 'brwpar1',\n",
    "        'btbwar', 'btnwar', 'btywar', 'bucmot2', 'buggna', 'bugtan',\n",
    "        'buhvir', 'bulori', 'burwar1', 'bushti', 'butsal1', 'buwtea',\n",
    "        'cacgoo1', 'cacwre', 'calqua', 'caltow', 'cangoo', 'canwar',\n",
    "        'carchi', 'carwre', 'casfin', 'caskin', 'caster1', 'casvir',\n",
    "        'categr', 'ccbfin', 'cedwax', 'chbant1', 'chbchi', 'chbwre1',\n",
    "        'chcant2', 'chispa', 'chswar', 'cinfly2', 'clanut', 'clcrob',\n",
    "        'cliswa', 'cobtan1', 'cocwoo1', 'cogdov', 'colcha1', 'coltro1',\n",
    "        'comgol', 'comgra', 'comloo', 'commer', 'compau', 'compot1',\n",
    "        'comrav', 'comyel', 'coohaw', 'cotfly1', 'cowscj1', 'cregua1',\n",
    "        'creoro1', 'crfpar', 'cubthr', 'daejun', 'dowwoo', 'ducfly', 'dusfly',\n",
    "        'easblu', 'easkin', 'easmea', 'easpho', 'eastow', 'eawpew', 'eletro',\n",
    "        'eucdov', 'eursta', 'fepowl', 'fiespa', 'flrtan1', 'foxspa', 'gadwal',\n",
    "        'gamqua', 'gartro1', 'gbbgul', 'gbwwre1', 'gcrwar', 'gilwoo',\n",
    "        'gnttow', 'gnwtea', 'gocfly1', 'gockin', 'gocspa', 'goftyr1',\n",
    "        'gohque1', 'goowoo1', 'grasal1', 'grbani', 'grbher3', 'grcfly',\n",
    "        'greegr', 'grekis', 'grepew', 'grethr1', 'gretin1', 'greyel',\n",
    "        'grhcha1', 'grhowl', 'grnher', 'grnjay', 'grtgra', 'grycat',\n",
    "        'gryhaw2', 'gwfgoo', 'haiwoo', 'heptan', 'hergul', 'herthr',\n",
    "        'herwar', 'higmot1', 'hofwoo1', 'houfin', 'houspa', 'houwre',\n",
    "        'hutvir', 'incdov', 'indbun', 'kebtou1', 'killde', 'labwoo', 'larspa',\n",
    "        'laufal1', 'laugul', 'lazbun', 'leafly', 'leasan', 'lesgol', 'lesgre1',\n",
    "        'lesvio1', 'linspa', 'linwoo1', 'littin1', 'lobdow', 'lobgna5', 'logshr',\n",
    "        'lotduc', 'lotman1', 'lucwar', 'macwar', 'magwar', 'mallar3', 'marwre',\n",
    "        'mastro1', 'meapar', 'melbla1', 'monoro1', 'mouchi', 'moudov', 'mouela1',\n",
    "        'mouqua', 'mouwar', 'mutswa', 'naswar', 'norcar', 'norfli', 'normoc', 'norpar',\n",
    "        'norsho', 'norwat', 'nrwswa', 'nutwoo', 'oaktit', 'obnthr1', 'ocbfly1',\n",
    "        'oliwoo1', 'olsfly', 'orbeup1', 'orbspa1', 'orcpar', 'orcwar', 'orfpar',\n",
    "        'osprey', 'ovenbi1', 'pabspi1', 'paltan1', 'palwar', 'pasfly', 'pavpig2',\n",
    "        'phivir', 'pibgre', 'pilwoo', 'pinsis', 'pirfly1', 'plawre1', 'plaxen1',\n",
    "        'plsvir', 'plupig2', 'prowar', 'purfin', 'purgal2', 'putfru1', 'pygnut',\n",
    "        'rawwre1', 'rcatan1', 'rebnut', 'rebsap', 'rebwoo', 'redcro', 'reevir1',\n",
    "        'rehbar1', 'relpar', 'reshaw', 'rethaw', 'rewbla', 'ribgul', 'rinkin1',\n",
    "        'roahaw', 'robgro', 'rocpig', 'rotbec', 'royter1', 'rthhum', 'rtlhum',\n",
    "        'ruboro1', 'rubpep1', 'rubrob', 'rubwre1', 'ruckin', 'rucspa1', 'rucwar',\n",
    "        'rucwar1', 'rudpig', 'rudtur', 'rufhum', 'rugdov', 'rumfly1', 'runwre1',\n",
    "        'rutjac1', 'saffin', 'sancra', 'sander', 'savspa', 'saypho', 'scamac1',\n",
    "        'scatan', 'scbwre1', 'scptyr1', 'scrtan1', 'semplo', 'shicow', 'sibtan2',\n",
    "        'sinwre1', 'sltred', 'smbani', 'snogoo', 'sobtyr1', 'socfly1', 'solsan',\n",
    "        'sonspa', 'soulap1', 'sposan', 'spotow', 'spvear1', 'squcuc1', 'stbori',\n",
    "        'stejay', 'sthant1', 'sthwoo1', 'strcuc1', 'strfly1', 'strsal1', 'stvhum2',\n",
    "        'subfly', 'sumtan', 'swaspa', 'swathr', 'tenwar', 'thbeup1', 'thbkin',\n",
    "        'thswar1', 'towsol', 'treswa', 'trogna1', 'trokin', 'tromoc', 'tropar',\n",
    "        'tropew1', 'tuftit', 'tunswa', 'veery', 'verdin', 'vigswa', 'warvir',\n",
    "        'wbwwre1', 'webwoo1', 'wegspa1', 'wesant1', 'wesblu', 'weskin', 'wesmea',\n",
    "        'westan', 'wewpew', 'whbman1', 'whbnut', 'whcpar', 'whcsee1', 'whcspa',\n",
    "        'whevir', 'whfpar1', 'whimbr', 'whiwre1', 'whtdov', 'whtspa', 'whwbec1',\n",
    "        'whwdov', 'wilfly', 'willet1', 'wilsni1', 'wiltur', 'wlswar', 'wooduc',\n",
    "        'woothr', 'wrenti', 'y00475', 'yebcha', 'yebela1', 'yebfly', 'yebori1',\n",
    "        'yebsap', 'yebsee1', 'yefgra1', 'yegvir', 'yehbla', 'yehcar1', 'yelgro',\n",
    "        'yelwar', 'yeofly1', 'yerwar', 'yeteup1', 'yetvir']\n",
    "\n",
    "    ######################\n",
    "    # Loaders #\n",
    "    ######################\n",
    "    loader_params = {\n",
    "        \"train\": {\n",
    "            \"batch_size\": 64,\n",
    "            \"num_workers\": 20,\n",
    "            \"shuffle\": True\n",
    "        },\n",
    "        \"valid\": {\n",
    "            \"batch_size\": 64,\n",
    "            \"num_workers\": 20,\n",
    "            \"shuffle\": False\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"batch_size\": 64,\n",
    "            \"num_workers\": 20,\n",
    "            \"shuffle\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ######################\n",
    "    # Split #\n",
    "    ######################\n",
    "    split = \"StratifiedKFold\"\n",
    "    split_params = {\n",
    "        \"n_splits\": 5,\n",
    "        \"shuffle\": True,\n",
    "        \"random_state\": 1213\n",
    "    }\n",
    "\n",
    "    ######################\n",
    "    # Model #\n",
    "    ######################\n",
    "    base_model_name = \"tf_efficientnet_b0_ns\"\n",
    "    pooling = \"max\"\n",
    "    pretrained = True\n",
    "    num_classes = 397\n",
    "    in_channels = 1\n",
    "\n",
    "    ######################\n",
    "    # Criterion #\n",
    "    ######################\n",
    "    loss_name = \"BCEFocal2WayLoss\"\n",
    "    loss_params: dict = {}\n",
    "\n",
    "    ######################\n",
    "    # Optimizer #\n",
    "    ######################\n",
    "    optimizer_name = \"Adam\"\n",
    "    base_optimizer = \"Adam\"\n",
    "    optimizer_params = {\n",
    "        \"lr\": 0.001\n",
    "    }\n",
    "    # For SAM optimizer\n",
    "    base_optimizer = \"Adam\"\n",
    "\n",
    "    ######################\n",
    "    # Scheduler #\n",
    "    ######################\n",
    "    scheduler_name = \"CosineAnnealingLR\"\n",
    "    scheduler_params = {\n",
    "        \"T_max\": 10\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-invention",
   "metadata": {
    "papermill": {
     "duration": 0.017681,
     "end_time": "2021-04-04T00:58:07.030285",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.012604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "shaped-norwegian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:07.070674Z",
     "iopub.status.busy": "2021-04-04T00:58:07.070167Z",
     "iopub.status.idle": "2021-04-04T00:58:07.080321Z",
     "shell.execute_reply": "2021-04-04T00:58:07.079809Z"
    },
    "papermill": {
     "duration": 0.032308,
     "end_time": "2021-04-04T00:58:07.080433",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.048125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_SR = 32000\n",
    "TEST = (len(list(Path(\"../input/birdclef-2021/test_soundscapes/\").glob(\"*.ogg\"))) != 0)\n",
    "if TEST:\n",
    "    DATADIR = Path(\"../input/birdclef-2021/test_soundscapes/\")\n",
    "else:\n",
    "    DATADIR = Path(\"../input/birdclef-2021/train_soundscapes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exciting-spencer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:07.120189Z",
     "iopub.status.busy": "2021-04-04T00:58:07.119655Z",
     "iopub.status.idle": "2021-04-04T00:58:07.147356Z",
     "shell.execute_reply": "2021-04-04T00:58:07.147734Z"
    },
    "papermill": {
     "duration": 0.049517,
     "end_time": "2021-04-04T00:58:07.147874",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.098357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20152_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57610_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7843_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42907_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7019_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54955_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10534_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2782_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11254_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7954_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26746_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18003_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31928_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>51010_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21767_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14473_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44957_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50878_COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28933_SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26709_SSW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id\n",
       "0   20152_SSW\n",
       "1   57610_COR\n",
       "2    7843_SSW\n",
       "3   42907_SSW\n",
       "4    7019_COR\n",
       "5   54955_SSW\n",
       "6   10534_SSW\n",
       "7    2782_SSW\n",
       "8   11254_COR\n",
       "9    7954_COR\n",
       "10  26746_COR\n",
       "11  18003_COR\n",
       "12  31928_COR\n",
       "13  51010_SSW\n",
       "14  21767_COR\n",
       "15  14473_SSW\n",
       "16  44957_COR\n",
       "17  50878_COR\n",
       "18  28933_SSW\n",
       "19  26709_SSW"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_audios = list(DATADIR.glob(\"*.ogg\"))\n",
    "all_audio_ids = [\"_\".join(audio_id.name.split(\"_\")[:2]) for audio_id in all_audios]\n",
    "submission_df = pd.DataFrame({\n",
    "    \"row_id\": all_audio_ids\n",
    "})\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-addition",
   "metadata": {
    "papermill": {
     "duration": 0.018674,
     "end_time": "2021-04-04T00:58:07.185409",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.166735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supported-relation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:07.247588Z",
     "iopub.status.busy": "2021-04-04T00:58:07.236633Z",
     "iopub.status.idle": "2021-04-04T00:58:07.265206Z",
     "shell.execute_reply": "2021-04-04T00:58:07.264759Z"
    },
    "papermill": {
     "duration": 0.061292,
     "end_time": "2021-04-04T00:58:07.265331",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.204039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def do_mixup(x: torch.Tensor, mixup_lambda: torch.Tensor):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes\n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0::2].transpose(0, -1) * mixup_lambda[0::2] +\n",
    "           x[1::2].transpose(0, -1) * mixup_lambda[1::2]).transpose(0, -1)\n",
    "    return out\n",
    "\n",
    "\n",
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(\n",
    "                self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return torch.from_numpy(np.array(mixup_lambdas, dtype=np.float32))\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    output = F.interpolate(\n",
    "        framewise_output.unsqueeze(1),\n",
    "        size=(frames_num, framewise_output.size(2)),\n",
    "        align_corners=True,\n",
    "        mode=\"bilinear\").squeeze(1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def gem(x: torch.Tensor, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1. / p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f\"(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})\"\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimmSED(nn.Module):\n",
    "    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n",
    "        super().__init__()\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=CFG.n_fft, hop_length=CFG.hop_length,\n",
    "                                                 win_length=CFG.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n",
    "                                                 freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=CFG.sample_rate, n_fft=CFG.n_fft,\n",
    "                                                 n_mels=CFG.n_mels, fmin=CFG.fmin, fmax=CFG.fmax, ref=1.0, amin=1e-10, top_db=None,\n",
    "                                                 freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n",
    "                                               freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            base_model_name, pretrained=pretrained, in_chans=in_channels)\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        if hasattr(base_model, \"fc\"):\n",
    "            in_features = base_model.fc.in_features\n",
    "        else:\n",
    "            in_features = base_model.classifier.in_features\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlockV2(\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "        init_bn(self.bn0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.spectrogram_extractor(input)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        x = x.transpose(2, 3)\n",
    "        # (batch_size, channels, freq, frames)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # (batch_size, channels, frames)\n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        # channel smoothing\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        interpolate_ratio = frames_num // segmentwise_output.size(1)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            \"framewise_output\": framewise_output,\n",
    "            \"segmentwise_output\": segmentwise_output,\n",
    "            \"logit\": logit,\n",
    "            \"framewise_logit\": framewise_logit,\n",
    "            \"clipwise_output\": clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-mailing",
   "metadata": {
    "papermill": {
     "duration": 0.01842,
     "end_time": "2021-04-04T00:58:07.302652",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.284232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elect-screen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:07.348240Z",
     "iopub.status.busy": "2021-04-04T00:58:07.347464Z",
     "iopub.status.idle": "2021-04-04T00:58:07.350467Z",
     "shell.execute_reply": "2021-04-04T00:58:07.350062Z"
    },
    "papermill": {
     "duration": 0.029168,
     "end_time": "2021-04-04T00:58:07.350593",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.321425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(torchdata.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, clip: np.ndarray,\n",
    "                 waveform_transforms=None):\n",
    "        self.df = df\n",
    "        self.clip = clip\n",
    "        self.waveform_transforms=waveform_transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = 32000\n",
    "        sample = self.df.loc[idx, :]\n",
    "        row_id = sample.row_id\n",
    "\n",
    "        end_seconds = int(sample.seconds)\n",
    "        start_seconds = int(end_seconds - 5)\n",
    "\n",
    "        start_index = SR * start_seconds\n",
    "        end_index = SR * end_seconds\n",
    "\n",
    "        y = self.clip[start_index:end_index].astype(np.float32)\n",
    "\n",
    "        y = np.nan_to_num(y)\n",
    "\n",
    "        if self.waveform_transforms:\n",
    "            y = self.waveform_transforms(y)\n",
    "\n",
    "        y = np.nan_to_num(y)\n",
    "\n",
    "        return y, row_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contrary-dress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:07.433541Z",
     "iopub.status.busy": "2021-04-04T00:58:07.412500Z",
     "iopub.status.idle": "2021-04-04T00:58:07.435965Z",
     "shell.execute_reply": "2021-04-04T00:58:07.435521Z"
    },
    "papermill": {
     "duration": 0.066618,
     "end_time": "2021-04-04T00:58:07.436086",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.369468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(phase: str):\n",
    "    transforms = CFG.transforms\n",
    "    if transforms is None:\n",
    "        return None\n",
    "    else:\n",
    "        if transforms[phase] is None:\n",
    "            return None\n",
    "        trns_list = []\n",
    "        for trns_conf in transforms[phase]:\n",
    "            trns_name = trns_conf[\"name\"]\n",
    "            trns_params = {} if trns_conf.get(\"params\") is None else \\\n",
    "                trns_conf[\"params\"]\n",
    "            if globals().get(trns_name) is not None:\n",
    "                trns_cls = globals()[trns_name]\n",
    "                trns_list.append(trns_cls(**trns_params))\n",
    "\n",
    "        if len(trns_list) > 0:\n",
    "            return Compose(trns_list)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def get_waveform_transforms(config: dict, phase: str):\n",
    "    return get_transforms(config, phase)\n",
    "\n",
    "\n",
    "def get_spectrogram_transforms(config: dict, phase: str):\n",
    "    transforms = config.get('spectrogram_transforms')\n",
    "    if transforms is None:\n",
    "        return None\n",
    "    else:\n",
    "        if transforms[phase] is None:\n",
    "            return None\n",
    "        trns_list = []\n",
    "        for trns_conf in transforms[phase]:\n",
    "            trns_name = trns_conf[\"name\"]\n",
    "            trns_params = {} if trns_conf.get(\"params\") is None else \\\n",
    "                trns_conf[\"params\"]\n",
    "            if hasattr(A, trns_name):\n",
    "                trns_cls = A.__getattribute__(trns_name)\n",
    "                trns_list.append(trns_cls(**trns_params))\n",
    "            else:\n",
    "                trns_cls = globals().get(trns_name)\n",
    "                if trns_cls is not None:\n",
    "                    trns_list.append(trns_cls(**trns_params))\n",
    "\n",
    "        if len(trns_list) > 0:\n",
    "            return A.Compose(trns_list, p=1.0)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "class Normalize:\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        max_vol = np.abs(y).max()\n",
    "        y_vol = y * 1 / max_vol\n",
    "        return np.asfortranarray(y_vol)\n",
    "\n",
    "\n",
    "class NewNormalize:\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        y_mm = y - y.mean()\n",
    "        return y_mm / y_mm.abs().max()\n",
    "\n",
    "\n",
    "class Compose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class AudioTransform:\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        if self.always_apply:\n",
    "            return self.apply(y)\n",
    "        else:\n",
    "            if np.random.rand() < self.p:\n",
    "                return self.apply(y)\n",
    "            else:\n",
    "                return y\n",
    "\n",
    "    def apply(self, y: np.ndarray):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class NoiseInjection(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_noise_level=0.5, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.noise_level = (0.0, max_noise_level)\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        noise_level = np.random.uniform(*self.noise_level)\n",
    "        noise = np.random.randn(len(y))\n",
    "        augmented = (y + noise * noise_level).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class GaussianNoise(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y ** 2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        white_noise = np.random.randn(len(y))\n",
    "        a_white = np.sqrt(white_noise ** 2).max()\n",
    "        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class PinkNoise(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "        self.min_snr = min_snr\n",
    "        self.max_snr = max_snr\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        snr = np.random.uniform(self.min_snr, self.max_snr)\n",
    "        a_signal = np.sqrt(y ** 2).max()\n",
    "        a_noise = a_signal / (10 ** (snr / 20))\n",
    "\n",
    "        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n",
    "        a_pink = np.sqrt(pink_noise ** 2).max()\n",
    "        augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class PitchShift(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_range=5, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.max_range = max_range\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        n_steps = np.random.randint(-self.max_range, self.max_range)\n",
    "        augmented = librosa.effects.pitch_shift(y, self.sr, n_steps)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "class TimeStretch(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, max_rate=1, sr=32000):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.max_rate = max_rate\n",
    "        self.sr = sr\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        rate = np.random.uniform(0, self.max_rate)\n",
    "        augmented = librosa.effects.time_stretch(y, rate)\n",
    "        return augmented\n",
    "\n",
    "\n",
    "def _db2float(db: float, amplitude=True):\n",
    "    if amplitude:\n",
    "        return 10**(db / 20)\n",
    "    else:\n",
    "        return 10 ** (db / 10)\n",
    "\n",
    "\n",
    "def volume_down(y: np.ndarray, db: float):\n",
    "    \"\"\"\n",
    "    Low level API for decreasing the volume\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: numpy.ndarray\n",
    "        stereo / monaural input audio\n",
    "    db: float\n",
    "        how much decibel to decrease\n",
    "    Returns\n",
    "    -------\n",
    "    applied: numpy.ndarray\n",
    "        audio with decreased volume\n",
    "    \"\"\"\n",
    "    applied = y * _db2float(-db)\n",
    "    return applied\n",
    "\n",
    "\n",
    "def volume_up(y: np.ndarray, db: float):\n",
    "    \"\"\"\n",
    "    Low level API for increasing the volume\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: numpy.ndarray\n",
    "        stereo / monaural input audio\n",
    "    db: float\n",
    "        how much decibel to increase\n",
    "    Returns\n",
    "    -------\n",
    "    applied: numpy.ndarray\n",
    "        audio with increased volume\n",
    "    \"\"\"\n",
    "    applied = y * _db2float(db)\n",
    "    return applied\n",
    "\n",
    "\n",
    "class RandomVolume(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, limit=10):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.limit = limit\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        db = np.random.uniform(-self.limit, self.limit)\n",
    "        if db >= 0:\n",
    "            return volume_up(y, db)\n",
    "        else:\n",
    "            return volume_down(y, db)\n",
    "\n",
    "\n",
    "class OneOf:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray):\n",
    "        n_trns = len(self.transforms)\n",
    "        trns_idx = np.random.choice(n_trns)\n",
    "        trns = self.transforms[trns_idx]\n",
    "        y = trns(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class CosineVolume(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=0.5, limit=10):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.limit = limit\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        db = np.random.uniform(-self.limit, self.limit)\n",
    "        cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)\n",
    "        dbs = _db2float(cosine * db)\n",
    "        return y * dbs\n",
    "\n",
    "\n",
    "def drop_stripes(image: np.ndarray, dim: int, drop_width: int, stripes_num: int):\n",
    "    total_width = image.shape[dim]\n",
    "    lowest_value = image.min()\n",
    "    for _ in range(stripes_num):\n",
    "        distance = np.random.randint(low=0, high=drop_width, size=(1,))[0]\n",
    "        begin = np.random.randint(\n",
    "            low=0, high=total_width - distance, size=(1,))[0]\n",
    "\n",
    "        if dim == 0:\n",
    "            image[begin:begin + distance] = lowest_value\n",
    "        elif dim == 1:\n",
    "            image[:, begin + distance] = lowest_value\n",
    "        elif dim == 2:\n",
    "            image[:, :, begin + distance] = lowest_value\n",
    "    return image\n",
    "\n",
    "\n",
    "class TimeFreqMasking(ImageOnlyTransform):\n",
    "    def __init__(self,\n",
    "                 time_drop_width: int,\n",
    "                 time_stripes_num: int,\n",
    "                 freq_drop_width: int,\n",
    "                 freq_stripes_num: int,\n",
    "                 always_apply=False,\n",
    "                 p=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.time_drop_width = time_drop_width\n",
    "        self.time_stripes_num = time_stripes_num\n",
    "        self.freq_drop_width = freq_drop_width\n",
    "        self.freq_stripes_num = freq_stripes_num\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        img_ = img.copy()\n",
    "        if img.ndim == 2:\n",
    "            img_ = drop_stripes(\n",
    "                img_, dim=0, drop_width=self.freq_drop_width, stripes_num=self.freq_stripes_num)\n",
    "            img_ = drop_stripes(\n",
    "                img_, dim=1, drop_width=self.time_drop_width, stripes_num=self.time_stripes_num)\n",
    "        return img_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-colleague",
   "metadata": {
    "papermill": {
     "duration": 0.01887,
     "end_time": "2021-04-04T00:58:07.474027",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.455157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "appropriate-royal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:07.517520Z",
     "iopub.status.busy": "2021-04-04T00:58:07.516717Z",
     "iopub.status.idle": "2021-04-04T00:58:07.519544Z",
     "shell.execute_reply": "2021-04-04T00:58:07.519136Z"
    },
    "papermill": {
     "duration": 0.026454,
     "end_time": "2021-04-04T00:58:07.519655",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.493201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_model_for_inference(model, path: Path):\n",
    "    if not torch.cuda.is_available():\n",
    "        ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    else:\n",
    "        ckpt = torch.load(path)\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "marked-uruguay",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:07.566979Z",
     "iopub.status.busy": "2021-04-04T00:58:07.566203Z",
     "iopub.status.idle": "2021-04-04T00:58:07.569319Z",
     "shell.execute_reply": "2021-04-04T00:58:07.568868Z"
    },
    "papermill": {
     "duration": 0.030902,
     "end_time": "2021-04-04T00:58:07.569437",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.538535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction_for_clip(test_df: pd.DataFrame, \n",
    "                        clip: np.ndarray, \n",
    "                        model, \n",
    "                        threshold=0.5):\n",
    "\n",
    "    dataset = TestDataset(df=test_df, \n",
    "                          clip=clip,\n",
    "                          waveform_transforms=get_transforms(phase=\"test\"))\n",
    "    loader = torchdata.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    prediction_dict = {}\n",
    "    for image, row_id in tqdm(loader):\n",
    "        row_id = row_id[0]\n",
    "        image = image.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            prediction = model(image)\n",
    "            proba = prediction[\"clipwise_output\"].detach().cpu().numpy().reshape(-1)\n",
    "\n",
    "        events = proba >= threshold\n",
    "        labels = np.argwhere(events).reshape(-1).tolist()\n",
    "\n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[row_id] = \"nocall\"\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: CFG.target_columns[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "            prediction_dict[row_id] = label_string\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fewer-portsmouth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:07.618203Z",
     "iopub.status.busy": "2021-04-04T00:58:07.617365Z",
     "iopub.status.idle": "2021-04-04T00:58:07.619946Z",
     "shell.execute_reply": "2021-04-04T00:58:07.619445Z"
    },
    "papermill": {
     "duration": 0.03127,
     "end_time": "2021-04-04T00:58:07.620068",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.588798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(test_audios,\n",
    "               weights_path: Path,\n",
    "               threshold=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TimmSED(base_model_name=CFG.base_model_name,\n",
    "                    pretrained=False,\n",
    "                    num_classes=CFG.num_classes,\n",
    "                    in_channels=CFG.in_channels)\n",
    "    model = prepare_model_for_inference(model, weights_path).to(device)\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for audio_path in test_audios:\n",
    "        with timer(f\"Loading {str(audio_path)}\", logger):\n",
    "            clip, _ = sf.read(audio_path)\n",
    "\n",
    "        seconds = []\n",
    "        row_ids = []\n",
    "        for second in range(5, 605, 5):\n",
    "            row_id = \"_\".join(audio_path.name.split(\"_\")[:2]) + f\"_{second}\"\n",
    "            seconds.append(second)\n",
    "            row_ids.append(row_id)\n",
    "            \n",
    "        test_df = pd.DataFrame({\n",
    "            \"row_id\": row_ids,\n",
    "            \"seconds\": seconds\n",
    "        })\n",
    "        with timer(f\"Prediction on {audio_path}\", logger):\n",
    "            prediction_dict = prediction_for_clip(test_df,\n",
    "                                                  clip=clip,\n",
    "                                                  model=model,\n",
    "                                                  threshold=threshold)\n",
    "        row_id = list(prediction_dict.keys())\n",
    "        birds = list(prediction_dict.values())\n",
    "        prediction_df = pd.DataFrame({\n",
    "            \"row_id\": row_id,\n",
    "            \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-coast",
   "metadata": {
    "papermill": {
     "duration": 0.019076,
     "end_time": "2021-04-04T00:58:07.658407",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.639331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dated-detail",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:58:08.063726Z",
     "iopub.status.busy": "2021-04-04T00:58:08.062480Z",
     "iopub.status.idle": "2021-04-04T00:59:07.839951Z",
     "shell.execute_reply": "2021-04-04T00:59:07.839454Z"
    },
    "papermill": {
     "duration": 60.162376,
     "end_time": "2021-04-04T00:59:07.840102",
     "exception": false,
     "start_time": "2021-04-04T00:58:07.677726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-04 00:58:15,279 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/20152_SSW_20170805.ogg] start\n",
      "2021-04-04 00:58:16,032 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/20152_SSW_20170805.ogg] done in 0.75 s\n",
      "2021-04-04 00:58:16,034 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/20152_SSW_20170805.ogg] start\n",
      "100%|| 120/120 [00:02<00:00, 46.55it/s]\n",
      "2021-04-04 00:58:18,619 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/20152_SSW_20170805.ogg] done in 2.59 s\n",
      "2021-04-04 00:58:18,622 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/57610_COR_20190904.ogg] start\n",
      "2021-04-04 00:58:19,385 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/57610_COR_20190904.ogg] done in 0.76 s\n",
      "2021-04-04 00:58:19,387 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/57610_COR_20190904.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 77.80it/s]\n",
      "2021-04-04 00:58:20,935 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/57610_COR_20190904.ogg] done in 1.55 s\n",
      "2021-04-04 00:58:20,937 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/7843_SSW_20170325.ogg] start\n",
      "2021-04-04 00:58:22,359 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/7843_SSW_20170325.ogg] done in 1.42 s\n",
      "2021-04-04 00:58:22,365 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/7843_SSW_20170325.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 70.23it/s]\n",
      "2021-04-04 00:58:24,083 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/7843_SSW_20170325.ogg] done in 1.72 s\n",
      "2021-04-04 00:58:24,085 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/42907_SSW_20170708.ogg] start\n",
      "2021-04-04 00:58:24,896 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/42907_SSW_20170708.ogg] done in 0.81 s\n",
      "2021-04-04 00:58:24,898 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/42907_SSW_20170708.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 63.72it/s]\n",
      "2021-04-04 00:58:26,786 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/42907_SSW_20170708.ogg] done in 1.89 s\n",
      "2021-04-04 00:58:26,788 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/7019_COR_20190904.ogg] start\n",
      "2021-04-04 00:58:27,628 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/7019_COR_20190904.ogg] done in 0.84 s\n",
      "2021-04-04 00:58:27,631 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/7019_COR_20190904.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 74.59it/s]\n",
      "2021-04-04 00:58:29,246 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/7019_COR_20190904.ogg] done in 1.62 s\n",
      "2021-04-04 00:58:29,248 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/54955_SSW_20170617.ogg] start\n",
      "2021-04-04 00:58:30,066 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/54955_SSW_20170617.ogg] done in 0.82 s\n",
      "2021-04-04 00:58:30,068 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/54955_SSW_20170617.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 71.07it/s]\n",
      "2021-04-04 00:58:31,762 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/54955_SSW_20170617.ogg] done in 1.69 s\n",
      "2021-04-04 00:58:31,764 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/10534_SSW_20170429.ogg] start\n",
      "2021-04-04 00:58:32,547 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/10534_SSW_20170429.ogg] done in 0.78 s\n",
      "2021-04-04 00:58:32,550 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/10534_SSW_20170429.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 77.36it/s]\n",
      "2021-04-04 00:58:34,107 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/10534_SSW_20170429.ogg] done in 1.56 s\n",
      "2021-04-04 00:58:34,108 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/2782_SSW_20170701.ogg] start\n",
      "2021-04-04 00:58:35,021 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/2782_SSW_20170701.ogg] done in 0.91 s\n",
      "2021-04-04 00:58:35,023 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/2782_SSW_20170701.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 66.81it/s]\n",
      "2021-04-04 00:58:36,824 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/2782_SSW_20170701.ogg] done in 1.80 s\n",
      "2021-04-04 00:58:36,826 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/11254_COR_20190904.ogg] start\n",
      "2021-04-04 00:58:37,637 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/11254_COR_20190904.ogg] done in 0.81 s\n",
      "2021-04-04 00:58:37,640 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/11254_COR_20190904.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 72.42it/s]\n",
      "2021-04-04 00:58:39,302 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/11254_COR_20190904.ogg] done in 1.66 s\n",
      "2021-04-04 00:58:39,304 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/7954_COR_20190923.ogg] start\n",
      "2021-04-04 00:58:40,148 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/7954_COR_20190923.ogg] done in 0.84 s\n",
      "2021-04-04 00:58:40,151 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/7954_COR_20190923.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 71.78it/s]\n",
      "2021-04-04 00:58:41,827 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/7954_COR_20190923.ogg] done in 1.68 s\n",
      "2021-04-04 00:58:41,829 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/26746_COR_20191004.ogg] start\n",
      "2021-04-04 00:58:42,682 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/26746_COR_20191004.ogg] done in 0.85 s\n",
      "2021-04-04 00:58:42,686 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/26746_COR_20191004.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 71.57it/s]\n",
      "2021-04-04 00:58:44,366 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/26746_COR_20191004.ogg] done in 1.68 s\n",
      "2021-04-04 00:58:44,368 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/18003_COR_20190904.ogg] start\n",
      "2021-04-04 00:58:45,156 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/18003_COR_20190904.ogg] done in 0.79 s\n",
      "2021-04-04 00:58:45,158 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/18003_COR_20190904.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 72.46it/s]\n",
      "2021-04-04 00:58:46,819 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/18003_COR_20190904.ogg] done in 1.66 s\n",
      "2021-04-04 00:58:46,821 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/31928_COR_20191004.ogg] start\n",
      "2021-04-04 00:58:47,723 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/31928_COR_20191004.ogg] done in 0.90 s\n",
      "2021-04-04 00:58:47,729 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/31928_COR_20191004.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 71.37it/s]\n",
      "2021-04-04 00:58:49,419 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/31928_COR_20191004.ogg] done in 1.69 s\n",
      "2021-04-04 00:58:49,421 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/51010_SSW_20170513.ogg] start\n",
      "2021-04-04 00:58:50,191 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/51010_SSW_20170513.ogg] done in 0.77 s\n",
      "2021-04-04 00:58:50,193 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/51010_SSW_20170513.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 74.35it/s]\n",
      "2021-04-04 00:58:51,812 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/51010_SSW_20170513.ogg] done in 1.62 s\n",
      "2021-04-04 00:58:51,815 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/21767_COR_20190904.ogg] start\n",
      "2021-04-04 00:58:52,642 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/21767_COR_20190904.ogg] done in 0.83 s\n",
      "2021-04-04 00:58:52,644 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/21767_COR_20190904.ogg] start\n",
      "100%|| 120/120 [00:02<00:00, 56.74it/s]\n",
      "2021-04-04 00:58:54,764 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/21767_COR_20190904.ogg] done in 2.12 s\n",
      "2021-04-04 00:58:54,769 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/14473_SSW_20170701.ogg] start\n",
      "2021-04-04 00:58:55,654 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/14473_SSW_20170701.ogg] done in 0.89 s\n",
      "2021-04-04 00:58:55,657 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/14473_SSW_20170701.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 67.75it/s]\n",
      "2021-04-04 00:58:57,565 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/14473_SSW_20170701.ogg] done in 1.91 s\n",
      "2021-04-04 00:58:57,567 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/44957_COR_20190923.ogg] start\n",
      "2021-04-04 00:58:58,308 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/44957_COR_20190923.ogg] done in 0.74 s\n",
      "2021-04-04 00:58:58,310 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/44957_COR_20190923.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 64.23it/s]\n",
      "2021-04-04 00:59:00,184 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/44957_COR_20190923.ogg] done in 1.87 s\n",
      "2021-04-04 00:59:00,186 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/50878_COR_20191004.ogg] start\n",
      "2021-04-04 00:59:00,979 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/50878_COR_20191004.ogg] done in 0.79 s\n",
      "2021-04-04 00:59:00,981 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/50878_COR_20191004.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 72.69it/s]\n",
      "2021-04-04 00:59:02,636 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/50878_COR_20191004.ogg] done in 1.66 s\n",
      "2021-04-04 00:59:02,638 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/28933_SSW_20170408.ogg] start\n",
      "2021-04-04 00:59:03,571 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/28933_SSW_20170408.ogg] done in 0.93 s\n",
      "2021-04-04 00:59:03,574 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/28933_SSW_20170408.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 73.45it/s]\n",
      "2021-04-04 00:59:05,214 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/28933_SSW_20170408.ogg] done in 1.64 s\n",
      "2021-04-04 00:59:05,216 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/26709_SSW_20170701.ogg] start\n",
      "2021-04-04 00:59:06,028 - INFO - [Loading ../input/birdclef-2021/train_soundscapes/26709_SSW_20170701.ogg] done in 0.81 s\n",
      "2021-04-04 00:59:06,030 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/26709_SSW_20170701.ogg] start\n",
      "100%|| 120/120 [00:01<00:00, 73.27it/s]\n",
      "2021-04-04 00:59:07,673 - INFO - [Prediction on ../input/birdclef-2021/train_soundscapes/26709_SSW_20170701.ogg] done in 1.64 s\n"
     ]
    }
   ],
   "source": [
    "weights_path = Path(\"../input/birdclef2021-effnetb0-starter-weight/best.pth\")\n",
    "submission = prediction(test_audios=all_audios,\n",
    "                        weights_path=weights_path,\n",
    "                        threshold=0.5)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "supported-steam",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-04T00:59:08.101169Z",
     "iopub.status.busy": "2021-04-04T00:59:08.100314Z",
     "iopub.status.idle": "2021-04-04T00:59:08.114233Z",
     "shell.execute_reply": "2021-04-04T00:59:08.113751Z"
    },
    "papermill": {
     "duration": 0.14595,
     "end_time": "2021-04-04T00:59:08.114357",
     "exception": false,
     "start_time": "2021-04-04T00:59:07.968407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>birds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20152_SSW_5</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20152_SSW_10</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20152_SSW_15</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20152_SSW_20</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20152_SSW_25</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>26709_SSW_580</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>26709_SSW_585</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>26709_SSW_590</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>26709_SSW_595</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>26709_SSW_600</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             row_id   birds\n",
       "0       20152_SSW_5  nocall\n",
       "1      20152_SSW_10  nocall\n",
       "2      20152_SSW_15  nocall\n",
       "3      20152_SSW_20  nocall\n",
       "4      20152_SSW_25  nocall\n",
       "...             ...     ...\n",
       "2395  26709_SSW_580  nocall\n",
       "2396  26709_SSW_585  nocall\n",
       "2397  26709_SSW_590  nocall\n",
       "2398  26709_SSW_595  nocall\n",
       "2399  26709_SSW_600  nocall\n",
       "\n",
       "[2400 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-anxiety",
   "metadata": {
    "papermill": {
     "duration": 0.126659,
     "end_time": "2021-04-04T00:59:08.367522",
     "exception": false,
     "start_time": "2021-04-04T00:59:08.240863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 131.804406,
   "end_time": "2021-04-04T00:59:10.968341",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-04T00:56:59.163935",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
